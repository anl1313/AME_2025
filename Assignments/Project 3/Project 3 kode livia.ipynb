{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the Police Public Contact Survey (PPCS) dataset: `ppcs_cc.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Libs and py-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# importing libs and py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import w8_logit as logit\n",
    "import w8_probit as probit\n",
    "import w8_estimation as est\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of 'anyuseofforce_coded':\n",
      "anyuseofforce_coded\n",
      "0    0.994999\n",
      "1    0.005001\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dat = pd.read_csv('ppcs_cc.csv')\n",
    "\n",
    "# Inspect distribution of the target variable\n",
    "print(\"\\nDistribution of 'anyuseofforce_coded':\")\n",
    "print(dat['anyuseofforce_coded'].value_counts(normalize=True))\n",
    "\n",
    "# Inspect value counts for categorical variables\n",
    "categorical_vars = [\"sblack\", \"shisp\", \"swhite\", \"sother\", \"smale\", \"omajblack\", \n",
    "                    \"omajhisp\", \"omajwhite\", \"omajother\", \"osplit\", \"inctype_lin\", \"sbehavior\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Full Sample       Swhite       Sblack        Shisp  \\\n",
      "Variable                                                                     \n",
      "sblack                     0.110555     0.000000     1.000000     0.000000   \n",
      "shisp                      0.101606     0.000000     0.000000     1.000000   \n",
      "swhite                     0.739142     1.000000     0.000000     0.000000   \n",
      "sother                     0.048697     0.000000     0.000000     0.000000   \n",
      "smale                      0.529613     0.521368     0.519048     0.585492   \n",
      "sage                      41.010003    42.147792    39.183333    36.225389   \n",
      "sempl                      0.695446     0.699786     0.688095     0.676166   \n",
      "sincome                    2.164780     2.218305     1.935714     1.997409   \n",
      "spop                       1.362727     1.271011     1.657143     1.652850   \n",
      "daytime                    0.666491     0.680912     0.621429     0.642487   \n",
      "inctype_lin                1.958410     1.957621     1.966667     1.953368   \n",
      "omajblack                  0.060805     0.048789     0.159524     0.046632   \n",
      "omajhisp                   0.023954     0.015313     0.045238     0.069948   \n",
      "omajwhite                  0.903659     0.929487     0.773810     0.865285   \n",
      "omajother                  0.011582     0.006410     0.021429     0.018135   \n",
      "osplit                     0.000000     0.000000     0.000000     0.000000   \n",
      "sbehavior                  0.065017     0.059117     0.083333     0.077720   \n",
      "year                    2011.000000  2011.000000  2011.000000  2011.000000   \n",
      "anyuseofforce_coded        0.005001     0.003205     0.007143     0.015544   \n",
      "Number of Observations  3799.000000  2808.000000   420.000000   386.000000   \n",
      "\n",
      "                             Sother  \n",
      "Variable                             \n",
      "sblack                     0.000000  \n",
      "shisp                      0.000000  \n",
      "swhite                     0.000000  \n",
      "sother                     1.000000  \n",
      "smale                      0.562162  \n",
      "sage                      37.870270  \n",
      "sempl                      0.686486  \n",
      "sincome                    2.221622  \n",
      "spop                       1.481081  \n",
      "daytime                    0.600000  \n",
      "inctype_lin                1.962162  \n",
      "omajblack                  0.048649  \n",
      "omajhisp                   0.010811  \n",
      "omajwhite                  0.886486  \n",
      "omajother                  0.054054  \n",
      "osplit                     0.000000  \n",
      "sbehavior                  0.086486  \n",
      "year                    2011.000000  \n",
      "anyuseofforce_coded        0.005405  \n",
      "Number of Observations   185.000000  \n"
     ]
    }
   ],
   "source": [
    "# Define groups for demographic categories\n",
    "group_vars = [\"swhite\", \"sblack\", \"shisp\", \"sother\"]\n",
    "\n",
    "# List of all variables for which we want to compute means\n",
    "all_vars = dat.columns\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "summary_table = pd.DataFrame()\n",
    "\n",
    "# Calculate the overall mean for each variable\n",
    "overall_means = dat[all_vars].mean()\n",
    "summary_table[\"Variable\"] = all_vars\n",
    "summary_table[\"Full Sample\"] = overall_means.values\n",
    "\n",
    "# Calculate the mean for each variable within each group\n",
    "for group in group_vars:\n",
    "    group_means = dat.loc[dat[group] == 1, all_vars].mean()\n",
    "    summary_table[group.capitalize()] = group_means.values\n",
    "\n",
    "# Add a row for \"Number of Observations\"\n",
    "num_obs_row = pd.DataFrame({\n",
    "    \"Variable\": [\"Number of Observations\"],\n",
    "    \"Full Sample\": [dat.shape[0]],\n",
    "    **{group.capitalize(): [dat.loc[dat[group] == 1].shape[0]] for group in group_vars}\n",
    "})\n",
    "\n",
    "# Append the \"Number of Observations\" row to the summary table\n",
    "summary_table = pd.concat([summary_table, num_obs_row], ignore_index=True)\n",
    "\n",
    "# Format the table for display\n",
    "summary_table = summary_table.set_index(\"Variable\")\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary table for assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach lanbels to data\n",
    "labels = {\n",
    "    'sblack': 'Black',\n",
    "    'shisp': 'Hispanic',\n",
    "    'swhite': 'White',\n",
    "    'sother': 'Other race',\n",
    "    'sage': 'Age',\n",
    "    'sempl': 'Employed last week or not',\n",
    "    'smale': 'Male',\n",
    "    'spop': 'Population size of civilian\\'s address',\n",
    "    'sincome': 'Income (categorical)',\n",
    "    'sbehavior': 'Behavior of civilian in encounter',\n",
    "    'omajwhite': 'Officer unit majorly white',\n",
    "    'omajother': 'Officer unit majorly other',\n",
    "    'omajblack': 'Officer unit majorly black',\n",
    "    'omajhisp': 'Officer unit majorly hispanic',\n",
    "    'osplit': 'Officer unit split race',\n",
    "    'daytime': 'Time of encounter',\n",
    "    'year': 'Year',\n",
    "    'inctype_lin': 'Incident type',\n",
    "    'anyuseofforce_coded': 'Any use of force by officer'}\n",
    "\n",
    "data_labeled = dat.rename(columns=labels)\n",
    "data_labeled.columns\n",
    "# table with summary statistics conditional on race and interaction\n",
    "# a. make columns for each race and full sample\n",
    "full_sample = dat\n",
    "white_only = dat[dat['swhite'] == 1]\n",
    "black_only = dat[dat['sblack'] == 1]\n",
    "hispanic_only = dat[dat['shisp'] == 1]\n",
    "other_only = dat[dat['sother'] == 1 ]\n",
    "groups = [full_sample, white_only, black_only, hispanic_only, other_only]\n",
    "group_names = ['Full sample', 'White only', 'Black only', 'Hispanic only', 'Other only']\n",
    "variables = ['sage','sempl', 'smale','sincome', 'spop', 'sbehavior', 'omajwhite', \n",
    "             'omajblack', 'omajhisp', 'omajother', 'osplit', 'daytime', \n",
    "             'inctype_lin', 'anyuseofforce_coded']\n",
    "variables_labeled = [labels[var] for var in variables]\n",
    "#####################################################\n",
    "# create empty dataframe to store summary statistics\n",
    "summary_stats = pd.DataFrame(columns=group_names, index=variables_labeled)\n",
    "# append two columns for p-values from t-tests between white vs black and hispanic vs white\n",
    "summary_stats['p-value (Black vs White)'] = np.nan\n",
    "summary_stats['p-value (Hispanic vs White)'] = np.nan\n",
    "summary_stats.index.name = 'Variable'\n",
    "for i, group in enumerate(groups):\n",
    "    summary_stats.iloc[:, i] = group[variables].mean().round(2) #mean\n",
    "    # t-test means of black vs white and hispanic vs white\n",
    "    if group_names[i] == 'Black only':\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_val = ttest_ind(black_only[variables], white_only[variables], equal_var=False, nan_policy='omit')\n",
    "        summary_stats['p-value (Black vs White)'] = p_val.round(2)\n",
    "    if group_names[i] == 'Hispanic only':\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_val = ttest_ind(hispanic_only[variables], white_only[variables], equal_var=False, nan_policy='omit')\n",
    "        summary_stats['p-value (Hispanic vs White)'] = p_val.round(2)\n",
    "\n",
    "#####################################################\n",
    "summary_stats.to_latex('summary_stats.tex', index=True, decimal=',', float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyuseofforce_coded</th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>sage</th>\n",
       "      <th>sagesq</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>51.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>50.41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>57.76</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>62.41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anyuseofforce_coded  const  sblack  shisp  sother  smale  sempl  \\\n",
       "3794                    0    1.0       0      0       0      0      1   \n",
       "3795                    0    1.0       0      0       0      0      0   \n",
       "3796                    0    1.0       0      0       0      0      0   \n",
       "3797                    0    1.0       0      0       0      0      0   \n",
       "3798                    0    1.0       0      0       0      0      0   \n",
       "\n",
       "      sincome  spop  sage  sagesq  daytime  inctype_lin  omajblack  omajhisp  \\\n",
       "3794        3     1   7.2   51.84        0            1          0         0   \n",
       "3795        2     1   7.1   50.41        1            2          0         0   \n",
       "3796        1     1   7.6   57.76        1            2          0         0   \n",
       "3797        3     4   7.9   62.41        1            2          0         0   \n",
       "3798        2     1   7.5   56.25        1            2          0         0   \n",
       "\n",
       "      omajother  sbehavior  \n",
       "3794          0          1  \n",
       "3795          0          0  \n",
       "3796          0          0  \n",
       "3797          0          0  \n",
       "3798          0          0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare labels    \n",
    "y_lab = 'anyuseofforce_coded'\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother', 'sbehavior']\n",
    "\n",
    "dat['sage'] = dat['sage'] / 10\n",
    "dat['sagesq'] = dat.sage * dat.sage \n",
    "\n",
    "# create extra variables \n",
    "N = dat.shape[0]\n",
    "dat['const'] = np.ones((N,))\n",
    "\n",
    "# Rebuild the dataset\n",
    "dat = dat[[y_lab] + x_lab].copy()\n",
    "\n",
    "# Check for missing data\n",
    "assert dat.notnull().all(axis=1).all(), 'Missing values detected. Clean your data!'\n",
    "dat.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Full Sample\n",
      "Variable                        \n",
      "anyuseofforce_coded     1.000000\n",
      "const                   1.000000\n",
      "sblack                  0.157895\n",
      "shisp                   0.315789\n",
      "sother                  0.052632\n",
      "smale                   0.789474\n",
      "sempl                   0.473684\n",
      "sincome                 2.052632\n",
      "spop                    1.947368\n",
      "sage                    3.078947\n",
      "sagesq                 10.666842\n",
      "daytime                 0.473684\n",
      "inctype_lin             1.684211\n",
      "omajblack               0.000000\n",
      "omajhisp                0.052632\n",
      "omajother               0.000000\n",
      "sbehavior               0.526316\n"
     ]
    }
   ],
   "source": [
    "# descriptive of who's been victim to police violence\n",
    "violence = dat[dat['anyuseofforce_coded']==1] \n",
    "\n",
    "# List of all variables for which we want to compute means\n",
    "all_vars = violence.columns\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "summary_table = pd.DataFrame()\n",
    "\n",
    "# Calculate the overall mean for each variable\n",
    "overall_means = violence[all_vars].mean()\n",
    "summary_table[\"Variable\"] = all_vars\n",
    "summary_table[\"Full Sample\"] = overall_means.values\n",
    "\n",
    "# Format the table for display\n",
    "summary_table = summary_table.set_index(\"Variable\")\n",
    "print(summary_table)\n",
    "\n",
    "# Optional: Save the table to a CSV for further analysis\n",
    "summary_table.to_latex('violence.csv')\n",
    "# sep issues with omajblack and omajother\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(3799, 16)\n"
     ]
    }
   ],
   "source": [
    "# Extract y and X\n",
    "y = dat[y_lab].values\n",
    "x = dat[x_lab].values\n",
    "K = x.shape[1]\n",
    "\n",
    "print(K)\n",
    "print(np.shape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate using probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022253\n",
      "         Iterations: 159\n",
      "         Function evaluations: 2958\n",
      "         Gradient evaluations: 174\n"
     ]
    }
   ],
   "source": [
    "# Initialize starting values\n",
    "theta0 = probit.starting_values(y, x)\n",
    "\n",
    "# Estimate model with probit\n",
    "probit_results = est.estimate(probit.q, theta0, y, x, cov_type='Sandwich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer succeeded after 159 iter. (2958 func. evals.). Final criterion:  0.02225.\n",
      "Probit, y = anyuseofforce_coded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-2.6161</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>-3.7622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.2042</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.6833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shisp</th>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.2382</td>\n",
       "      <td>1.7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smale</th>\n",
       "      <td>0.5619</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>2.6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sempl</th>\n",
       "      <td>-0.5001</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>-2.2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome</th>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spop</th>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>2.6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>1.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagesq</th>\n",
       "      <td>-0.0791</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>-1.5856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.1416</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>-0.7158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inctype_lin</th>\n",
       "      <td>-0.7421</td>\n",
       "      <td>0.2585</td>\n",
       "      <td>-2.8706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajblack</th>\n",
       "      <td>-2.6389</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>-5.1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajhisp</th>\n",
       "      <td>-0.3379</td>\n",
       "      <td>0.4014</td>\n",
       "      <td>-0.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajother</th>\n",
       "      <td>-2.3897</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>-6.6839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbehavior</th>\n",
       "      <td>1.0670</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>5.5591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              theta      se       t\n",
       "const       -2.6161  0.6954 -3.7622\n",
       "sblack       0.2042  0.2988  0.6833\n",
       "shisp        0.4162  0.2382  1.7468\n",
       "sother       0.1051  0.4384  0.2397\n",
       "smale        0.5619  0.2102  2.6736\n",
       "sempl       -0.5001  0.2205 -2.2676\n",
       "sincome      0.1022  0.1243  0.8216\n",
       "spop         0.1988  0.0747  2.6626\n",
       "sage         0.4861  0.3719  1.3072\n",
       "sagesq      -0.0791  0.0499 -1.5856\n",
       "daytime     -0.1416  0.1978 -0.7158\n",
       "inctype_lin -0.7421  0.2585 -2.8706\n",
       "omajblack   -2.6389  0.5100 -5.1743\n",
       "omajhisp    -0.3379  0.4014 -0.8416\n",
       "omajother   -2.3897  0.3575 -6.6839\n",
       "sbehavior    1.0670  0.1919  5.5591"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probit_tab = est.print_table(x_lab, probit_results, title=f'Probit, y = {y_lab}')\n",
    "probit_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's Information Matrix Test for Probit Model Misspecification\n",
      "------------------------------------------------------------------\n",
      "Test Statistic: 2270.8817\n",
      "P-value: 0.0000\n",
      "Result: Reject the null hypothesis of correct model specification at the 5% significance level.\n"
     ]
    }
   ],
   "source": [
    "# White's information matrix test for model misspecification\n",
    "whites_test = probit.whites_imt_probit(probit_results['theta'], y, x)\n",
    "probit.print_test_stats(whites_test[0], whites_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate using Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022389\n",
      "         Iterations: 203\n",
      "         Function evaluations: 3604\n",
      "         Gradient evaluations: 212\n"
     ]
    }
   ],
   "source": [
    "# Initialize starting values\n",
    "theta0 = logit.starting_values(y, x)\n",
    "\n",
    "# Estimate model with logit\n",
    "logit_results = est.estimate(logit.q, theta0, y, x, cov_type='Sandwich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer succeeded after 203 iter. (3604 func. evals.). Final criterion:  0.02239.\n",
      "Logit, y = anyuseofforce_coded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-5.6105</td>\n",
       "      <td>1.9349</td>\n",
       "      <td>-2.8996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>0.5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shisp</th>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>1.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>-0.0945</td>\n",
       "      <td>1.3081</td>\n",
       "      <td>-0.0723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smale</th>\n",
       "      <td>1.1543</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>2.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sempl</th>\n",
       "      <td>-1.1609</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>-1.8880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome</th>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spop</th>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>2.5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>1.3028</td>\n",
       "      <td>1.1759</td>\n",
       "      <td>1.1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagesq</th>\n",
       "      <td>-0.2207</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>-1.3362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.3866</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>-0.7263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inctype_lin</th>\n",
       "      <td>-1.5712</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>-2.2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajblack</th>\n",
       "      <td>-8.2439</td>\n",
       "      <td>1.1940</td>\n",
       "      <td>-6.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajhisp</th>\n",
       "      <td>-0.5374</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>-0.6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajother</th>\n",
       "      <td>-6.3304</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>-9.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbehavior</th>\n",
       "      <td>2.5359</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>4.9432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              theta      se       t\n",
       "const       -5.6105  1.9349 -2.8996\n",
       "sblack       0.4362  0.8092  0.5390\n",
       "shisp        0.9404  0.6142  1.5312\n",
       "sother      -0.0945  1.3081 -0.0723\n",
       "smale        1.1543  0.5733  2.0135\n",
       "sempl       -1.1609  0.6149 -1.8880\n",
       "sincome      0.2021  0.3418  0.5914\n",
       "spop         0.4812  0.1903  2.5287\n",
       "sage         1.3028  1.1759  1.1079\n",
       "sagesq      -0.2207  0.1652 -1.3362\n",
       "daytime     -0.3866  0.5322 -0.7263\n",
       "inctype_lin -1.5712  0.6840 -2.2973\n",
       "omajblack   -8.2439  1.1940 -6.9044\n",
       "omajhisp    -0.5374  0.8020 -0.6701\n",
       "omajother   -6.3304  0.6337 -9.9904\n",
       "sbehavior    2.5359  0.5130  4.9432"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_tab = est.print_table(x_lab, logit_results, title=f'Logit, y = {y_lab}')\n",
    "logit_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's Information Matrix Test for Probit Model Misspecification\n",
      "------------------------------------------------------------------\n",
      "Test Statistic: 2412.3541\n",
      "P-value: 0.0000\n",
      "Result: Reject the null hypothesis of correct model specification at the 5% significance level.\n"
     ]
    }
   ],
   "source": [
    "# White's information matrix test for model misspecification\n",
    "whites_test = logit.whites_imt_logit(logit_results['theta'], y, x)\n",
    "logit.print_test_stats(whites_test[0], whites_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average partial effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimate\n",
       "sblack        0.002\n",
       "shispanic     0.006\n",
       "sother        0.001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating the average partial effects using the probit\n",
    "indices = [x_lab.index('sblack'), x_lab.index('shisp'), x_lab.index('sother')]  \n",
    "labels = ['sblack', 'shispanic', 'sother'] \n",
    "res_probit = probit.properties(x, probit_results['theta'],print_out = True,se=True,indices=indices, labels = labels)\n",
    "res_probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018157\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025581\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025581\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015862\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015862\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Bootstrap iteration 2 failed: Singular matrix\n",
      "Bootstrap iteration 2 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028591\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028591\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018354\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018354\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022920\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022920\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021041\n",
      "         Iterations: 103\n",
      "         Function evaluations: 1819\n",
      "         Gradient evaluations: 107\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021041\n",
      "         Iterations: 103\n",
      "         Function evaluations: 1819\n",
      "         Gradient evaluations: 107\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023759\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023759\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017658\n",
      "         Iterations: 114\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017658\n",
      "         Iterations: 114\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022980\n",
      "         Iterations: 116\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022980\n",
      "         Iterations: 116\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025741\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Bootstrap iteration 10 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025741\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Bootstrap iteration 10 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030644\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030644\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022003\n",
      "         Iterations: 99\n",
      "         Function evaluations: 1734\n",
      "         Gradient evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022003\n",
      "         Iterations: 99\n",
      "         Function evaluations: 1734\n",
      "         Gradient evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024714\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1581\n",
      "         Gradient evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024714\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1581\n",
      "         Gradient evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017513\n",
      "         Iterations: 125\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017513\n",
      "         Iterations: 125\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014142\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014142\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029176\n",
      "         Iterations: 93\n",
      "         Function evaluations: 1615\n",
      "         Gradient evaluations: 95\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029176\n",
      "         Iterations: 93\n",
      "         Function evaluations: 1615\n",
      "         Gradient evaluations: 95\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016394\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016394\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020902\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020902\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021699\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021699\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019331\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019331\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014888\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014888\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026827\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026827\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018026\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018026\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022796\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022796\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022353\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1802\n",
      "         Gradient evaluations: 106\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022353\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1802\n",
      "         Gradient evaluations: 106\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022949\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022949\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029727\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029727\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024191\n",
      "         Iterations: 92\n",
      "         Function evaluations: 1598\n",
      "         Gradient evaluations: 94\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024191\n",
      "         Iterations: 92\n",
      "         Function evaluations: 1598\n",
      "         Gradient evaluations: 94\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016594\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016594\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023240\n",
      "         Iterations: 96\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023240\n",
      "         Iterations: 96\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016288\n",
      "         Iterations: 100\n",
      "         Function evaluations: 1734\n",
      "         Gradient evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016288\n",
      "         Iterations: 100\n",
      "         Function evaluations: 1734\n",
      "         Gradient evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022627\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022627\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018274\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018274\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016691\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016691\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009485\n",
      "         Iterations: 99\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009485\n",
      "         Iterations: 99\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029076\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029076\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017191\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017191\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023280\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023280\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020718\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020718\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022199\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022199\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019599\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019599\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017710\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017710\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018652\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018652\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025549\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025549\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031325\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1581\n",
      "         Gradient evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031325\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1581\n",
      "         Gradient evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024703\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024703\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018393\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018393\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015999\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015999\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015269\n",
      "         Iterations: 142\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015269\n",
      "         Iterations: 142\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025493\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Bootstrap iteration 50 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025493\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Bootstrap iteration 50 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022000\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022000\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013067\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1972\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013067\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1972\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023580\n",
      "         Iterations: 108\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023580\n",
      "         Iterations: 108\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014948\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014948\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013740\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013740\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032973\n",
      "         Iterations: 108\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032973\n",
      "         Iterations: 108\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020858\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020858\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029820\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029820\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024753\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024753\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023966\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023966\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021201\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021201\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027212\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027212\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012820\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012820\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020895\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020895\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014364\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014364\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020522\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020522\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015880\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015880\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019690\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Bootstrap iteration 68 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019690\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Bootstrap iteration 68 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021397\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021397\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021405\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021405\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023333\n",
      "         Iterations: 88\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023333\n",
      "         Iterations: 88\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024843\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024843\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022827\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022827\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019752\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019752\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021954\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021954\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016806\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016806\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016506\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016506\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015744\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015744\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021577\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021577\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014079\n",
      "         Iterations: 111\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014079\n",
      "         Iterations: 111\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020720\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020720\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015123\n",
      "         Iterations: 142\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015123\n",
      "         Iterations: 142\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026856\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026856\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011658\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2380\n",
      "         Gradient evaluations: 140\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011658\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2380\n",
      "         Gradient evaluations: 140\n",
      "Bootstrap iteration 84 failed: Singular matrix\n",
      "Bootstrap iteration 84 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022245\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022245\n",
      "         Iterations: 115\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012606\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1683\n",
      "         Gradient evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012606\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1683\n",
      "         Gradient evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022494\n",
      "         Iterations: 74\n",
      "         Function evaluations: 1326\n",
      "         Gradient evaluations: 78\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022494\n",
      "         Iterations: 74\n",
      "         Function evaluations: 1326\n",
      "         Gradient evaluations: 78\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015922\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015922\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020202\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020202\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016995\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1751\n",
      "         Gradient evaluations: 103\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016995\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1751\n",
      "         Gradient evaluations: 103\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018101\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018101\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020151\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1785\n",
      "         Gradient evaluations: 105\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020151\n",
      "         Iterations: 101\n",
      "         Function evaluations: 1785\n",
      "         Gradient evaluations: 105\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020893\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020893\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013830\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013830\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024743\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024743\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028019\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028019\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016186\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016186\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014944\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Bootstrap iteration 98 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014944\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Bootstrap iteration 98 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022294\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Bootstrap iteration 99 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022294\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Bootstrap iteration 99 failed: Singular matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boostrapped SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Boostrapped SE\n",
       "Black           0.004004\n",
       "Hispanic        0.004275\n",
       "Other           0.004757"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bootstrap SEs\n",
    "se = probit.bootstrap(y, x, probit_results['theta'], indices, nB=100)\n",
    "formatted_se =pd.DataFrame(se, index=[\"Black\", \"Hispanic\", \"Other\"], columns=[\"Boostrapped SE\"]).round(6)\n",
    "formatted_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimate\n",
       "sblack        0.002\n",
       "shispanic     0.005\n",
       "sother       -0.000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimating the average partial effects using the logit\n",
    "indices = [x_lab.index('sblack'), x_lab.index('shisp'), x_lab.index('sother')]  \n",
    "labels = ['sblack', 'shispanic', 'sother']  \n",
    "res_logit = logit.properties(x, logit_results['theta'],print_out = True,se=True,indices=indices, labels = labels)\n",
    "res_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021399\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Bootstrap iteration 0 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025381\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025381\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019848\n",
      "         Iterations: 185\n",
      "         Function evaluations: 3162\n",
      "         Gradient evaluations: 186\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019848\n",
      "         Iterations: 185\n",
      "         Function evaluations: 3162\n",
      "         Gradient evaluations: 186\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016133\n",
      "         Iterations: 169\n",
      "         Function evaluations: 2890\n",
      "         Gradient evaluations: 170\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016133\n",
      "         Iterations: 169\n",
      "         Function evaluations: 2890\n",
      "         Gradient evaluations: 170\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016472\n",
      "         Iterations: 166\n",
      "         Function evaluations: 2839\n",
      "         Gradient evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016472\n",
      "         Iterations: 166\n",
      "         Function evaluations: 2839\n",
      "         Gradient evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022996\n",
      "         Iterations: 177\n",
      "         Function evaluations: 3043\n",
      "         Gradient evaluations: 179\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022996\n",
      "         Iterations: 177\n",
      "         Function evaluations: 3043\n",
      "         Gradient evaluations: 179\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017979\n",
      "         Iterations: 154\n",
      "         Function evaluations: 2635\n",
      "         Gradient evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017979\n",
      "         Iterations: 154\n",
      "         Function evaluations: 2635\n",
      "         Gradient evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016723\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016723\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028668\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028668\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018461\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018461\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016446\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016446\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015692\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015692\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023846\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023846\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024075\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024075\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023750\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023750\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022619\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022619\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1666\n",
      "         Gradient evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020487\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020487\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016803\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016803\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025585\n",
      "         Iterations: 89\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025585\n",
      "         Iterations: 89\n",
      "         Function evaluations: 1547\n",
      "         Gradient evaluations: 91\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019723\n",
      "         Iterations: 162\n",
      "         Function evaluations: 2805\n",
      "         Gradient evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019723\n",
      "         Iterations: 162\n",
      "         Function evaluations: 2805\n",
      "         Gradient evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024913\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024913\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020479\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020479\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019934\n",
      "         Iterations: 123\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019934\n",
      "         Iterations: 123\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015558\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015558\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015444\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015444\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019196\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2873\n",
      "         Gradient evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019196\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2873\n",
      "         Gradient evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013780\n",
      "         Iterations: 176\n",
      "         Function evaluations: 3009\n",
      "         Gradient evaluations: 177\n",
      "Bootstrap iteration 26 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013780\n",
      "         Iterations: 176\n",
      "         Function evaluations: 3009\n",
      "         Gradient evaluations: 177\n",
      "Bootstrap iteration 26 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017086\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017086\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017563\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017563\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022286\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022286\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019870\n",
      "         Iterations: 151\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019870\n",
      "         Iterations: 151\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019249\n",
      "         Iterations: 151\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019249\n",
      "         Iterations: 151\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024662\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024662\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021501\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021501\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023518\n",
      "         Iterations: 164\n",
      "         Function evaluations: 2805\n",
      "         Gradient evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023518\n",
      "         Iterations: 164\n",
      "         Function evaluations: 2805\n",
      "         Gradient evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016218\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016218\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013430\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013430\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015709\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015709\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025347\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025347\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028518\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028518\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025073\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025073\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023348\n",
      "         Iterations: 115\n",
      "         Function evaluations: 1972\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023348\n",
      "         Iterations: 115\n",
      "         Function evaluations: 1972\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014222\n",
      "         Iterations: 157\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014222\n",
      "         Iterations: 157\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018310\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018310\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020359\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020359\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020132\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020132\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018081\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018081\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015752\n",
      "         Iterations: 148\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015752\n",
      "         Iterations: 148\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017421\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017421\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028010\n",
      "         Iterations: 144\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028010\n",
      "         Iterations: 144\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032456\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032456\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029195\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029195\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016403\n",
      "         Iterations: 182\n",
      "         Function evaluations: 3111\n",
      "         Gradient evaluations: 183\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016403\n",
      "         Iterations: 182\n",
      "         Function evaluations: 3111\n",
      "         Gradient evaluations: 183\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015416\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015416\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022588\n",
      "         Iterations: 178\n",
      "         Function evaluations: 3043\n",
      "         Gradient evaluations: 179\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022588\n",
      "         Iterations: 178\n",
      "         Function evaluations: 3043\n",
      "         Gradient evaluations: 179\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016812\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016812\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017704\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017704\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022076\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022076\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021980\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021980\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012512\n",
      "         Iterations: 158\n",
      "         Function evaluations: 2703\n",
      "         Gradient evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012512\n",
      "         Iterations: 158\n",
      "         Function evaluations: 2703\n",
      "         Gradient evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018738\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018738\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018962\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018962\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020688\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020688\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031088\n",
      "         Iterations: 170\n",
      "         Function evaluations: 2907\n",
      "         Gradient evaluations: 171\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031088\n",
      "         Iterations: 170\n",
      "         Function evaluations: 2907\n",
      "         Gradient evaluations: 171\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018559\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018559\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015589\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015589\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019826\n",
      "         Iterations: 176\n",
      "         Function evaluations: 3026\n",
      "         Gradient evaluations: 178\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019826\n",
      "         Iterations: 176\n",
      "         Function evaluations: 3026\n",
      "         Gradient evaluations: 178\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016453\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016453\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022865\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022865\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024834\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024834\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023486\n",
      "         Iterations: 79\n",
      "         Function evaluations: 1377\n",
      "         Gradient evaluations: 81\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023486\n",
      "         Iterations: 79\n",
      "         Function evaluations: 1377\n",
      "         Gradient evaluations: 81\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020319\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020319\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025076\n",
      "         Iterations: 154\n",
      "         Function evaluations: 2635\n",
      "         Gradient evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025076\n",
      "         Iterations: 154\n",
      "         Function evaluations: 2635\n",
      "         Gradient evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019329\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2380\n",
      "         Gradient evaluations: 140\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019329\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2380\n",
      "         Gradient evaluations: 140\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015746\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015746\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020657\n",
      "         Iterations: 180\n",
      "         Function evaluations: 3094\n",
      "         Gradient evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020657\n",
      "         Iterations: 180\n",
      "         Function evaluations: 3094\n",
      "         Gradient evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032149\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.032149\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024642\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024642\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020232\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020232\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013714\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013714\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018703\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018703\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015608\n",
      "         Iterations: 168\n",
      "         Function evaluations: 2873\n",
      "         Gradient evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015608\n",
      "         Iterations: 168\n",
      "         Function evaluations: 2873\n",
      "         Gradient evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023220\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023220\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021762\n",
      "         Iterations: 161\n",
      "         Function evaluations: 2754\n",
      "         Gradient evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021762\n",
      "         Iterations: 161\n",
      "         Function evaluations: 2754\n",
      "         Gradient evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021482\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021482\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018633\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018633\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022476\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022476\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016199\n",
      "         Iterations: 156\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016199\n",
      "         Iterations: 156\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024753\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2856\n",
      "         Gradient evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024753\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2856\n",
      "         Gradient evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011679\n",
      "         Iterations: 155\n",
      "         Function evaluations: 2652\n",
      "         Gradient evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011679\n",
      "         Iterations: 155\n",
      "         Function evaluations: 2652\n",
      "         Gradient evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025972\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025972\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014909\n",
      "         Iterations: 153\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014909\n",
      "         Iterations: 153\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018912\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018912\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013890\n",
      "         Iterations: 153\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013890\n",
      "         Iterations: 153\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016428\n",
      "         Iterations: 150\n",
      "         Function evaluations: 2567\n",
      "         Gradient evaluations: 151\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016428\n",
      "         Iterations: 150\n",
      "         Function evaluations: 2567\n",
      "         Gradient evaluations: 151\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023361\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023361\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027093\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027093\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019504\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1683\n",
      "         Gradient evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019504\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1683\n",
      "         Gradient evaluations: 99\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021638\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021638\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014282\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014282\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boostrapped SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>0.004208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>0.005370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.004330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Boostrapped SE\n",
       "Black           0.004208\n",
       "Hispanic        0.005370\n",
       "Other           0.004330"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bootstrap SEs\n",
    "se = logit.bootstrap(y, x, logit_results['theta'], indices, nB=100)\n",
    "formatted_se =pd.DataFrame(se, index=[\"Black\", \"Hispanic\", \"Other\"], columns=[\"Boostrapped SE\"]).round(6)\n",
    "formatted_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining different fixed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10\n",
      "19.42\n",
      "2.16\n",
      "1.36\n"
     ]
    }
   ],
   "source": [
    "#means of the regressors\n",
    "print(f\"{np.mean(dat['sage']):.2f}\")\n",
    "print(f\"{np.mean(dat['sagesq']):.2f}\")\n",
    "print(f\"{np.mean(dat['sincome']):.2f}\")\n",
    "print(f\"{np.mean(dat['spop']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sage</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "      <th>sagesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_me</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  sblack  shisp  sother  smale  sage  sempl  sincome  spop  \\\n",
       "x_me    1.0     0.0    0.0     0.0    1.0   2.5    0.0      1.0   4.0   \n",
       "\n",
       "      daytime  inctype_lin  omajblack  omajhisp  omajother  sbehavior  sagesq  \n",
       "x_me      5.0          1.0        0.0       0.0        0.0        1.0    6.25  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original vector\n",
    "# make vector of stereotypical white young man \n",
    "x_lab = ['const', 'sblack', 'shisp', 'sother', \n",
    "         'smale', 'sage', 'sempl', 'sincome',\n",
    "         'spop', 'daytime', 'inctype_lin', 'omajblack',\n",
    "         'omajhisp', 'omajother', 'sbehavior','sagesq']\n",
    "\n",
    "x_me = np.array([1, 0, 0, 0,\n",
    "                 1, 2.5, 0, 1,\n",
    "                 4, 5, 1, 0, \n",
    "                 0, 0, 1, 6.25]).reshape(1, -1)\n",
    "\n",
    "pd.DataFrame(x_me, columns=x_lab, index=['x_me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sage</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "      <th>sagesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_me</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  sblack  shisp  sother  smale  sage  sempl  sincome  spop  \\\n",
       "x_me    1.0     0.0    0.0     0.0    0.0   4.5    1.0      3.0   2.0   \n",
       "\n",
       "      daytime  inctype_lin  omajblack  omajhisp  omajother  sbehavior  sagesq  \n",
       "x_me      2.0          1.0        0.0       0.0        0.0        1.0   20.25  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make vector of stereotypical white old woman\n",
    "x_lab = ['const', 'sblack', 'shisp', 'sother', \n",
    "         'smale', 'sage', 'sempl', 'sincome',\n",
    "         'spop', 'daytime', 'inctype_lin', 'omajblack',\n",
    "         'omajhisp', 'omajother', 'sbehavior','sagesq']\n",
    "\n",
    "x_me = np.array([1, 0, 0, 0,\n",
    "                 0, 4.5, 1, 3,\n",
    "                 2, 2, 1, 0, \n",
    "                 0, 0, 1, 20.25]).reshape(1, -1)\n",
    "\n",
    "pd.DataFrame(x_me, columns=x_lab, index=['x_me'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switcing race "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sage</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "      <th>sagesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_me2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  sblack  shisp  sother  smale  sage  sempl  sincome  spop  \\\n",
       "x_me2    1.0     1.0    0.0     0.0    1.0   2.5    0.0      1.0   4.0   \n",
       "\n",
       "       daytime  inctype_lin  omajblack  omajhisp  omajother  sbehavior  sagesq  \n",
       "x_me2      5.0          1.0        0.0       0.0        0.0        1.0    6.25  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k=1: black \n",
    "#k=2: hispanic\n",
    "#k=3: other\n",
    "\n",
    "k = 1\n",
    "x_me2 = x_me.copy()\n",
    "x_me2[:, k] = 1   \n",
    "pd.DataFrame(x_me2, columns=x_lab, index=['x_me2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch coef from probit model\n",
    "b_pr = probit_tab.theta.values\n",
    "# find marginal effect as difference in predicted probabilities\n",
    "me_race_pr = probit.G(x_me2@b_pr) - probit.G(x_me@b_pr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gradient\n",
    "gx0 = norm.pdf(x_me@b_pr)\n",
    "gx2 = norm.pdf(x_me2@b_pr)\n",
    "grad_d_pr = gx2*x_me2 - gx0*x_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate std. errors\n",
    "def get_se(grad, cov):\n",
    "    # calculate variance-covariance matrix\n",
    "    cov_me = grad@cov@grad.T\n",
    "    # return squareroot of variance = se\n",
    "    return np.sqrt(np.diag(cov_me))\n",
    "\n",
    "se_d_pr = get_se(grad_d_pr, probit_results['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marginal Effect</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.259265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Marginal Effect      s.e.         t\n",
       "Var                                     \n",
       "0           0.002253  0.008689  0.259265"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table with results\n",
    "me_dict = {'Marginal Effect': me_race_pr[0],\n",
    "           's.e.':            se_d_pr}\n",
    "tab = pd.DataFrame(me_dict)\n",
    "tab['t'] = tab['Marginal Effect'] / tab['s.e.']\n",
    "tab.index.name = 'Var'\n",
    "tab.round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch coef from logit model\n",
    "b_lg = logit_tab.theta.values\n",
    "# cal diff in predicted probabilities\n",
    "me_race_lg = logit.G(x_me2@b_lg) - logit.G(x_me@b_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the logistic function exponential terms for x_me2 and x_me\n",
    "exp_x0_b = np.exp(-(x_me@b_lg))\n",
    "exp_x2_b = np.exp(-(x_me2@b_lg))\n",
    "grad_d_lg = (x_me2 * exp_x2_b)/ (1 + exp_x2_b)**2 - (x_me * exp_x0_b)/ (1 + exp_x0_b)**2\n",
    "se_d_lg = get_se(grad_d_lg, logit_results['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find p value for marginal effects\n",
    "from scipy.stats import norm\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.to_latex('me_probit_youngman_hisp.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_dict = {'Marginal Effect': me_race_lg[0],\n",
    "           's.e.':            se_d_lg}\n",
    "tab = pd.DataFrame(me_dict)\n",
    "tab['t'] = tab['Marginal Effect'] / tab['s.e.']\n",
    "tab.index.name = 'Var'\n",
    "tab.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.to_latex('me_logit_youngman_hisp.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table with probit and logit results for marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'me_probit_youngman.tex',\n",
    "    'me_probit_youngman_hisp.tex',\n",
    "    'me_logit_youngman.tex',\n",
    "    'me_logit_youngman_hisp.tex',\n",
    "    'me_probit_old_woman.tex',\n",
    "    'me_probit_old_woman_hisp.tex',\n",
    "    'me_logit_old_woman.tex',\n",
    "    'me_logit_old_woman.tex'\n",
    "]\n",
    "\n",
    "with open('combined_table.tex', 'w') as outfile:\n",
    "    outfile.write(r'\\begin{table}[ht!]' + '\\n')\n",
    "    outfile.write(r'\\centering' + '\\n')\n",
    "    outfile.write(r'\\caption{Marginal Effects from Probit and Logit Models}' + '\\n')\n",
    "    outfile.write(r'\\begin{tabular}{lccc}' + '\\n')\n",
    "    outfile.write(r'\\toprule' + '\\n')\n",
    "    \n",
    "    panels = ['Panel A: Probit, Young Man',\n",
    "              'Panel B: Probit, Young Man Hispanic',\n",
    "              'Panel C: Logit, young man',\n",
    "              'Panel D: Logit, young man, hispanic',\n",
    "              'Panel E: Probit, Old Woman',\n",
    "              'Panel F: Probit, Old Woman, hispanic',\n",
    "              'Panel G: Logit, Old Woman',\n",
    "              'Panel H: Logit, Old Woman, hispanic']\n",
    "\n",
    "    for panel_name, fname in zip(panels, files):\n",
    "        outfile.write(r'\\midrule' + '\\n')\n",
    "        outfile.write(r'\\multicolumn{4}{c}{\\textbf{' + panel_name + r'}} \\\\' + '\\n')\n",
    "        outfile.write(r'\\midrule' + '\\n')\n",
    "        with open(fname) as infile:\n",
    "            content = infile.read()\n",
    "            outfile.write(content + '\\n')\n",
    "    \n",
    "    outfile.write(r'\\bottomrule' + '\\n')\n",
    "    outfile.write(r'\\end{tabular}' + '\\n')\n",
    "    outfile.write(r'\\end{table}' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM test of probit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030440\n",
      "         Iterations: 37\n",
      "         Function evaluations: 195\n",
      "         Gradient evaluations: 39\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: smale, sempl, sincome, spop, sage, sagesq\n",
      "Degrees of freedom: 6\n",
      "LM Test Statistic: 23.5037\n",
      "P-value: 0.0006\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: daytime, inctype_lin, omajblack, omajhisp, omajother\n",
      "Degrees of freedom: 5\n",
      "LM Test Statistic: 2.4918\n",
      "P-value: 0.7777\n",
      "------------------------------------------------------------\n",
      "Result: Fail to reject H0 - additional variables are not significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: sbehavior\n",
      "Degrees of freedom: 1\n",
      "LM Test Statistic: 58.9636\n",
      "P-value: 0.0000\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# conduct LM tests of different model formulations\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother', 'sbehavior']\n",
    "\n",
    "y_lab = 'anyuseofforce_coded'\n",
    "x_lab_restricted = ['const', 'sblack', 'shisp', 'sother']\n",
    "x_restricted = dat[x_lab_restricted].values\n",
    "\n",
    "# a. Estimate restricted model\n",
    "theta0 = probit.starting_values(y, x_restricted)\n",
    "results_restricted = est.estimate(probit.q, theta0, y, x_restricted)\n",
    "theta_restricted = results_restricted['theta']\n",
    "\n",
    "# b. Prepare the additional variables to test\n",
    "# first augmentation\n",
    "x_lab_additional_1 = ['smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "x_additional_1 = dat[x_lab_additional_1].values\n",
    "# second augmentation\n",
    "x_lab_additional_2 = ['daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_additional_2 = dat[x_lab_additional_2].values\n",
    "# third augmentation\n",
    "x_lab_additional_3 = ['sbehavior']\n",
    "x_additional_3 = dat[x_lab_additional_3].values\n",
    "\n",
    "# c. Run the LM test\n",
    "# first augmentation\n",
    "stat, pval, df = probit.LM_test(y, x_restricted, theta_restricted, x_additional_1)\n",
    "# second\n",
    "stat2, pval2, df2 = probit.LM_test(y, x_restricted, theta_restricted, x_additional_2)\n",
    "#third\n",
    "stat3, pval3, df3 = probit.LM_test(y, x_restricted, theta_restricted, x_additional_3)\n",
    "# d. Print results\n",
    "probit.print_LM_test(stat, pval, df, var_names=x_lab_additional_1)\n",
    "probit.print_LM_test(stat2, pval2, df2, var_names=x_lab_additional_2)\n",
    "probit.print_LM_test(stat3, pval3, df3, var_names=x_lab_additional_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM test of logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030440\n",
      "         Iterations: 51\n",
      "         Function evaluations: 265\n",
      "         Gradient evaluations: 53\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: smale, sempl, sincome, spop, sage, sagesq\n",
      "Degrees of freedom: 6\n",
      "LM Test Statistic: 23.5757\n",
      "P-value: 0.0006\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: daytime, inctype_lin, omajblack, omajhisp, omajother\n",
      "Degrees of freedom: 5\n",
      "LM Test Statistic: 2.5265\n",
      "P-value: 0.7725\n",
      "------------------------------------------------------------\n",
      "Result: Fail to reject H0 - additional variables are not significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: sbehavior\n",
      "Degrees of freedom: 1\n",
      "LM Test Statistic: 56.7351\n",
      "P-value: 0.0000\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# conduct LM tests of different model formulations\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother', 'sbehavior']\n",
    "\n",
    "y_lab = 'anyuseofforce_coded'\n",
    "x_lab_restricted = ['const', 'sblack', 'shisp', 'sother']\n",
    "x_restricted = dat[x_lab_restricted].values\n",
    "\n",
    "# a. Estimate restricted model\n",
    "theta0 = logit.starting_values(y, x_restricted)\n",
    "results_restricted = est.estimate(logit.q, theta0, y, x_restricted)\n",
    "theta_restricted = results_restricted['theta']\n",
    "\n",
    "# b. Prepare the additional variables to test\n",
    "# first augmentation\n",
    "x_lab_additional_1 = ['smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "x_additional_1 = dat[x_lab_additional_1].values\n",
    "# second augmentation\n",
    "x_lab_additional_2 = ['daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_additional_2 = dat[x_lab_additional_2].values\n",
    "# third augmentation\n",
    "x_lab_additional_3 = ['sbehavior']\n",
    "x_additional_3 = dat[x_lab_additional_3].values\n",
    "\n",
    "# c.. Run the LM test\n",
    "# first augmentation\n",
    "stat, pval, df = logit.LM_test(y, x_restricted, theta_restricted, x_additional_1)\n",
    "# second\n",
    "stat2, pval2, df2 = logit.LM_test(y, x_restricted, theta_restricted, x_additional_2)\n",
    "#third\n",
    "stat3, pval3, df3 = logit.LM_test(y, x_restricted, theta_restricted, x_additional_3)\n",
    "# d. Print results\n",
    "logit.print_LM_test(stat, pval, df, var_names=x_lab_additional_1)\n",
    "logit.print_LM_test(stat2, pval2, df2, var_names=x_lab_additional_2)\n",
    "logit.print_LM_test(stat3, pval3, df3, var_names=x_lab_additional_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
