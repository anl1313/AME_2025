{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anna Livia, Jens and Freja \n",
    "\n",
    "This notebook uses the Police Public Contact Survey (PPCS) dataset: `ppcs_cc.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Libs and py-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import w8_logit as logit\n",
    "import w8_probit as probit\n",
    "import w8_estimation as est\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of 'anyuseofforce_coded':\n",
      "anyuseofforce_coded\n",
      "0    0.994999\n",
      "1    0.005001\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dat = pd.read_csv('ppcs_cc.csv')\n",
    "\n",
    "# Inspect distribution of the target variable\n",
    "print(\"\\nDistribution of 'anyuseofforce_coded':\")\n",
    "print(dat['anyuseofforce_coded'].value_counts(normalize=True))\n",
    "\n",
    "# Inspect value counts for categorical variables\n",
    "categorical_vars = [\"sblack\", \"shisp\", \"swhite\", \"sother\", \"smale\", \"omajblack\", \n",
    "                    \"omajhisp\", \"omajwhite\", \"omajother\", \"osplit\", \"inctype_lin\", \"sbehavior\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Full Sample       Swhite       Sblack        Shisp  \\\n",
      "Variable                                                                     \n",
      "sblack                     0.110555     0.000000     1.000000     0.000000   \n",
      "shisp                      0.101606     0.000000     0.000000     1.000000   \n",
      "swhite                     0.739142     1.000000     0.000000     0.000000   \n",
      "sother                     0.048697     0.000000     0.000000     0.000000   \n",
      "smale                      0.529613     0.521368     0.519048     0.585492   \n",
      "sage                      41.010003    42.147792    39.183333    36.225389   \n",
      "sempl                      0.695446     0.699786     0.688095     0.676166   \n",
      "sincome                    2.164780     2.218305     1.935714     1.997409   \n",
      "spop                       1.362727     1.271011     1.657143     1.652850   \n",
      "daytime                    0.666491     0.680912     0.621429     0.642487   \n",
      "inctype_lin                1.958410     1.957621     1.966667     1.953368   \n",
      "omajblack                  0.060805     0.048789     0.159524     0.046632   \n",
      "omajhisp                   0.023954     0.015313     0.045238     0.069948   \n",
      "omajwhite                  0.903659     0.929487     0.773810     0.865285   \n",
      "omajother                  0.011582     0.006410     0.021429     0.018135   \n",
      "osplit                     0.000000     0.000000     0.000000     0.000000   \n",
      "sbehavior                  0.065017     0.059117     0.083333     0.077720   \n",
      "year                    2011.000000  2011.000000  2011.000000  2011.000000   \n",
      "anyuseofforce_coded        0.005001     0.003205     0.007143     0.015544   \n",
      "Number of Observations  3799.000000  2808.000000   420.000000   386.000000   \n",
      "\n",
      "                             Sother  \n",
      "Variable                             \n",
      "sblack                     0.000000  \n",
      "shisp                      0.000000  \n",
      "swhite                     0.000000  \n",
      "sother                     1.000000  \n",
      "smale                      0.562162  \n",
      "sage                      37.870270  \n",
      "sempl                      0.686486  \n",
      "sincome                    2.221622  \n",
      "spop                       1.481081  \n",
      "daytime                    0.600000  \n",
      "inctype_lin                1.962162  \n",
      "omajblack                  0.048649  \n",
      "omajhisp                   0.010811  \n",
      "omajwhite                  0.886486  \n",
      "omajother                  0.054054  \n",
      "osplit                     0.000000  \n",
      "sbehavior                  0.086486  \n",
      "year                    2011.000000  \n",
      "anyuseofforce_coded        0.005405  \n",
      "Number of Observations   185.000000  \n"
     ]
    }
   ],
   "source": [
    "# Define groups for demographic categories\n",
    "group_vars = [\"swhite\", \"sblack\", \"shisp\", \"sother\"]\n",
    "\n",
    "# List of all variables for which we want to compute means\n",
    "all_vars = dat.columns\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "summary_table = pd.DataFrame()\n",
    "\n",
    "# Calculate the overall mean for each variable\n",
    "overall_means = dat[all_vars].mean()\n",
    "summary_table[\"Variable\"] = all_vars\n",
    "summary_table[\"Full Sample\"] = overall_means.values\n",
    "\n",
    "# Calculate the mean for each variable within each group\n",
    "for group in group_vars:\n",
    "    group_means = dat.loc[dat[group] == 1, all_vars].mean()\n",
    "    summary_table[group.capitalize()] = group_means.values\n",
    "\n",
    "# Add a row for \"Number of Observations\"\n",
    "num_obs_row = pd.DataFrame({\n",
    "    \"Variable\": [\"Number of Observations\"],\n",
    "    \"Full Sample\": [dat.shape[0]],\n",
    "    **{group.capitalize(): [dat.loc[dat[group] == 1].shape[0]] for group in group_vars}\n",
    "})\n",
    "\n",
    "# Append the \"Number of Observations\" row to the summary table\n",
    "summary_table = pd.concat([summary_table, num_obs_row], ignore_index=True)\n",
    "\n",
    "# Format the table for display\n",
    "summary_table = summary_table.set_index(\"Variable\")\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary table for assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach lanbels to data\n",
    "labels = {\n",
    "    'sblack': 'Black',\n",
    "    'shisp': 'Hispanic',\n",
    "    'swhite': 'White',\n",
    "    'sother': 'Other race',\n",
    "    'sage': 'Age',\n",
    "    'sempl': 'Employed last week or not',\n",
    "    'smale': 'Male',\n",
    "    'spop': 'Population size of civilian\\'s address',\n",
    "    'sincome': 'Income (categorical)',\n",
    "    'sbehavior': 'Behavior of civilian in encounter',\n",
    "    'omajwhite': 'Officer unit majorly white',\n",
    "    'omajother': 'Officer unit majorly other',\n",
    "    'omajblack': 'Officer unit majorly black',\n",
    "    'omajhisp': 'Officer unit majorly hispanic',\n",
    "    'osplit': 'Officer unit split race',\n",
    "    'daytime': 'Time of encounter',\n",
    "    'year': 'Year',\n",
    "    'inctype_lin': 'Incident type',\n",
    "    'anyuseofforce_coded': 'Any use of force by officer'}\n",
    "\n",
    "data_labeled = dat.rename(columns=labels)\n",
    "data_labeled.columns\n",
    "#Table with summary statistics conditional on race and interaction\n",
    "full_sample = dat\n",
    "white_only = dat[dat['swhite'] == 1]\n",
    "black_only = dat[dat['sblack'] == 1]\n",
    "hispanic_only = dat[dat['shisp'] == 1]\n",
    "other_only = dat[dat['sother'] == 1 ]\n",
    "groups = [full_sample, white_only, black_only, hispanic_only, other_only]\n",
    "group_names = ['Full sample', 'White only', 'Black only', 'Hispanic only', 'Other only']\n",
    "variables = ['sage','sempl', 'smale','sincome', 'spop', 'sbehavior', 'omajwhite', \n",
    "             'omajblack', 'omajhisp', 'omajother', 'osplit', 'daytime', \n",
    "             'inctype_lin', 'anyuseofforce_coded']\n",
    "variables_labeled = [labels[var] for var in variables]\n",
    "\n",
    "#####################################################\n",
    "#Create empty dataframe to store summary statistics\n",
    "summary_stats = pd.DataFrame(columns=group_names, index=variables_labeled)\n",
    "#Append two columns for p-values from t-tests between white vs black and hispanic vs white\n",
    "summary_stats['p-value (Black vs White)'] = np.nan\n",
    "summary_stats['p-value (Hispanic vs White)'] = np.nan\n",
    "summary_stats.index.name = 'Variable'\n",
    "for i, group in enumerate(groups):\n",
    "    summary_stats.iloc[:, i] = group[variables].mean().round(2) #mean\n",
    "    # t-test means of black vs white and hispanic vs white\n",
    "    if group_names[i] == 'Black only':\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_val = ttest_ind(black_only[variables], white_only[variables], equal_var=False, nan_policy='omit')\n",
    "        summary_stats['p-value (Black vs White)'] = p_val.round(2)\n",
    "    if group_names[i] == 'Hispanic only':\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_val = ttest_ind(hispanic_only[variables], white_only[variables], equal_var=False, nan_policy='omit')\n",
    "        summary_stats['p-value (Hispanic vs White)'] = p_val.round(2)\n",
    "\n",
    "#####################################################\n",
    "summary_stats.to_latex('summary_stats.tex', index=True, decimal=',', float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Full Sample\n",
      "Variable                        \n",
      "sblack                  0.157895\n",
      "shisp                   0.315789\n",
      "swhite                  0.473684\n",
      "sother                  0.052632\n",
      "smale                   0.789474\n",
      "sage                   30.789474\n",
      "sempl                   0.473684\n",
      "sincome                 2.052632\n",
      "spop                    1.947368\n",
      "daytime                 0.473684\n",
      "inctype_lin             1.684211\n",
      "omajblack               0.000000\n",
      "omajhisp                0.052632\n",
      "omajwhite               0.947368\n",
      "omajother               0.000000\n",
      "osplit                  0.000000\n",
      "sbehavior               0.526316\n",
      "year                 2011.000000\n",
      "anyuseofforce_coded     1.000000\n"
     ]
    }
   ],
   "source": [
    "#Descriptive of who's been victim to police violence\n",
    "violence = dat[dat['anyuseofforce_coded']==1] \n",
    "\n",
    "# List of all variables for which we want to compute means\n",
    "all_vars = violence.columns\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "summary_table = pd.DataFrame()\n",
    "\n",
    "# Calculate the overall mean for each variable\n",
    "overall_means = violence[all_vars].mean()\n",
    "summary_table[\"Variable\"] = all_vars\n",
    "summary_table[\"Full Sample\"] = overall_means.values\n",
    "\n",
    "# Format the table for display\n",
    "summary_table = summary_table.set_index(\"Variable\")\n",
    "print(summary_table)\n",
    "\n",
    "##########################################################\n",
    "summary_table.to_latex('violence.csv')\n",
    "#Sep issues with omajblack and omajother"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anyuseofforce_coded</th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>sage</th>\n",
       "      <th>sagesq</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>51.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>50.41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>57.76</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>62.41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anyuseofforce_coded  const  sblack  shisp  sother  smale  sempl  \\\n",
       "3794                    0    1.0       0      0       0      0      1   \n",
       "3795                    0    1.0       0      0       0      0      0   \n",
       "3796                    0    1.0       0      0       0      0      0   \n",
       "3797                    0    1.0       0      0       0      0      0   \n",
       "3798                    0    1.0       0      0       0      0      0   \n",
       "\n",
       "      sincome  spop  sage  sagesq  daytime  inctype_lin  omajblack  omajhisp  \\\n",
       "3794        3     1   7.2   51.84        0            1          0         0   \n",
       "3795        2     1   7.1   50.41        1            2          0         0   \n",
       "3796        1     1   7.6   57.76        1            2          0         0   \n",
       "3797        3     4   7.9   62.41        1            2          0         0   \n",
       "3798        2     1   7.5   56.25        1            2          0         0   \n",
       "\n",
       "      omajother  sbehavior  \n",
       "3794          0          1  \n",
       "3795          0          0  \n",
       "3796          0          0  \n",
       "3797          0          0  \n",
       "3798          0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declare labels for our different model specificiations   \n",
    "y_lab = 'anyuseofforce_coded'\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_lab = ['const', 'sblack', 'shisp', 'sother', 'smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq', 'daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother', 'sbehavior']\n",
    "\n",
    "dat['sage'] = dat['sage'] / 10\n",
    "dat['sagesq'] = dat.sage * dat.sage \n",
    "\n",
    "#Create extra variables \n",
    "N = dat.shape[0]\n",
    "dat['const'] = np.ones((N,))\n",
    "\n",
    "#Rebuild the dataset\n",
    "dat = dat[[y_lab] + x_lab].copy()\n",
    "\n",
    "#Check for missing data\n",
    "assert dat.notnull().all(axis=1).all(), 'Missing values detected. Clean your data!'\n",
    "dat.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(3799, 16)\n"
     ]
    }
   ],
   "source": [
    "#Extract y and X\n",
    "y = dat[y_lab].values\n",
    "x = dat[x_lab].values\n",
    "K = x.shape[1]\n",
    "#Check the shapes for the model specification\n",
    "print(K)\n",
    "print(np.shape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate using probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022253\n",
      "         Iterations: 161\n",
      "         Function evaluations: 3009\n",
      "         Gradient evaluations: 177\n",
      "Optimizer succeeded after 161 iter. (3009 func. evals.). Final criterion:  0.02225.\n",
      "Probit, y = anyuseofforce_coded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-2.6158</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>-3.7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.6835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shisp</th>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>1.7436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smale</th>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>2.6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sempl</th>\n",
       "      <td>-0.5003</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>-2.2672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome</th>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.8215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spop</th>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>2.6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>1.3053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagesq</th>\n",
       "      <td>-0.0791</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>-1.5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.1415</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>-0.7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inctype_lin</th>\n",
       "      <td>-0.7423</td>\n",
       "      <td>0.2585</td>\n",
       "      <td>-2.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajblack</th>\n",
       "      <td>-2.7076</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>-5.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajhisp</th>\n",
       "      <td>-0.3381</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>-0.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajother</th>\n",
       "      <td>-2.4694</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>-3.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbehavior</th>\n",
       "      <td>1.0670</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>5.5613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              theta      se       t\n",
       "const       -2.6158  0.6964 -3.7561\n",
       "sblack       0.2044  0.2991  0.6835\n",
       "shisp        0.4162  0.2387  1.7436\n",
       "sother       0.1049  0.4429  0.2369\n",
       "smale        0.5622  0.2103  2.6739\n",
       "sempl       -0.5003  0.2207 -2.2672\n",
       "sincome      0.1022  0.1244  0.8215\n",
       "spop         0.1988  0.0746  2.6633\n",
       "sage         0.4861  0.3724  1.3053\n",
       "sagesq      -0.0791  0.0499 -1.5845\n",
       "daytime     -0.1415  0.1979 -0.7151\n",
       "inctype_lin -0.7423  0.2585 -2.8713\n",
       "omajblack   -2.7076  0.4986 -5.4303\n",
       "omajhisp    -0.3381  0.4017 -0.8416\n",
       "omajother   -2.4694  0.7399 -3.3375\n",
       "sbehavior    1.0670  0.1919  5.5613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize starting values\n",
    "theta0 = probit.starting_values(y, x)\n",
    "\n",
    "#Estimate model with probit\n",
    "probit_results = est.estimate(probit.q, theta0, y, x, cov_type='Sandwich')\n",
    "\n",
    "#Print the results\n",
    "probit_tab = est.print_table(x_lab, probit_results, title=f'Probit, y = {y_lab}')\n",
    "probit_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's Information Matrix Test for Probit Model Misspecification\n",
      "------------------------------------------------------------------\n",
      "Test Statistic: 2268.3458\n",
      "P-value: 0.0000\n",
      "Result: Reject the null hypothesis of correct model specification at the 5% significance level.\n"
     ]
    }
   ],
   "source": [
    "# White's information matrix test for model misspecification\n",
    "whites_test = probit.whites_imt_probit(probit_results['theta'], y, x)\n",
    "probit.print_test_stats(whites_test[0], whites_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate using Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022389\n",
      "         Iterations: 203\n",
      "         Function evaluations: 3604\n",
      "         Gradient evaluations: 212\n",
      "Optimizer succeeded after 203 iter. (3604 func. evals.). Final criterion:  0.02239.\n",
      "Logit, y = anyuseofforce_coded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-5.6104</td>\n",
       "      <td>1.9351</td>\n",
       "      <td>-2.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.5409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shisp</th>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>1.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.2499</td>\n",
       "      <td>-0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smale</th>\n",
       "      <td>1.1543</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>2.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sempl</th>\n",
       "      <td>-1.1609</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>-1.8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sincome</th>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.5922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spop</th>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>2.5433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>1.3028</td>\n",
       "      <td>1.1769</td>\n",
       "      <td>1.1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagesq</th>\n",
       "      <td>-0.2207</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>-1.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daytime</th>\n",
       "      <td>-0.3866</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>-0.7253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inctype_lin</th>\n",
       "      <td>-1.5712</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>-2.2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajblack</th>\n",
       "      <td>-8.2290</td>\n",
       "      <td>1.0418</td>\n",
       "      <td>-7.8991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajhisp</th>\n",
       "      <td>-0.5375</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>-0.6711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omajother</th>\n",
       "      <td>-6.3168</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>-6.6093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbehavior</th>\n",
       "      <td>2.5359</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>4.9509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              theta      se       t\n",
       "const       -5.6104  1.9351 -2.8993\n",
       "sblack       0.4362  0.8065  0.5409\n",
       "shisp        0.9405  0.6122  1.5361\n",
       "sother      -0.0944  1.2499 -0.0755\n",
       "smale        1.1543  0.5735  2.0128\n",
       "sempl       -1.1609  0.6148 -1.8884\n",
       "sincome      0.2021  0.3414  0.5922\n",
       "spop         0.4812  0.1892  2.5433\n",
       "sage         1.3028  1.1769  1.1070\n",
       "sagesq      -0.2207  0.1653 -1.3354\n",
       "daytime     -0.3866  0.5330 -0.7253\n",
       "inctype_lin -1.5712  0.6836 -2.2986\n",
       "omajblack   -8.2290  1.0418 -7.8991\n",
       "omajhisp    -0.5375  0.8009 -0.6711\n",
       "omajother   -6.3168  0.9557 -6.6093\n",
       "sbehavior    2.5359  0.5122  4.9509"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize starting values\n",
    "theta0 = logit.starting_values(y, x)\n",
    "\n",
    "# Estimate model with logit\n",
    "logit_results = est.estimate(logit.q, theta0, y, x, cov_type='Sandwich')\n",
    "\n",
    "#Print the results\n",
    "logit_tab = est.print_table(x_lab, logit_results, title=f'Logit, y = {y_lab}')\n",
    "logit_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for misspecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's Information Matrix Test for Probit Model Misspecification\n",
      "------------------------------------------------------------------\n",
      "Test Statistic: 2412.3041\n",
      "P-value: 0.0000\n",
      "Result: Reject the null hypothesis of correct model specification at the 5% significance level.\n"
     ]
    }
   ],
   "source": [
    "# White's information matrix test for model misspecification\n",
    "whites_test = logit.whites_imt_logit(logit_results['theta'], y, x)\n",
    "logit.print_test_stats(whites_test[0], whites_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average partial effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimate\n",
       "sblack        0.002\n",
       "shispanic     0.006\n",
       "sother        0.001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimating the average partial effects using the probit\n",
    "indices = [x_lab.index('sblack'), x_lab.index('shisp'), x_lab.index('sother')]  \n",
    "labels = ['sblack', 'shispanic', 'sother'] \n",
    "\n",
    "#Print the average partial effects with standard errors\n",
    "res_probit = probit.properties(x, probit_results['theta'],print_out = True,se=True,indices=indices, labels = labels)\n",
    "res_probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023057\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023544\n",
      "         Iterations: 100\n",
      "         Function evaluations: 1751\n",
      "         Gradient evaluations: 103\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020586\n",
      "         Iterations: 78\n",
      "         Function evaluations: 1377\n",
      "         Gradient evaluations: 81\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017565\n",
      "         Iterations: 109\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021981\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1802\n",
      "         Gradient evaluations: 106\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025874\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018155\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013328\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Bootstrap iteration 7 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016617\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013366\n",
      "         Iterations: 95\n",
      "         Function evaluations: 1649\n",
      "         Gradient evaluations: 97\n",
      "Bootstrap iteration 9 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019613\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015311\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019176\n",
      "         Iterations: 125\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Bootstrap iteration 12 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018695\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022960\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023406\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021526\n",
      "         Iterations: 90\n",
      "         Function evaluations: 1564\n",
      "         Gradient evaluations: 92\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022640\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027779\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031169\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023506\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008698\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015025\n",
      "         Iterations: 100\n",
      "         Function evaluations: 1734\n",
      "         Gradient evaluations: 102\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020253\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022790\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014788\n",
      "         Iterations: 115\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017309\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1972\n",
      "         Gradient evaluations: 116\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015710\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022057\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019797\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020468\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023345\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017970\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025620\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023020\n",
      "         Iterations: 88\n",
      "         Function evaluations: 1530\n",
      "         Gradient evaluations: 90\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018353\n",
      "         Iterations: 106\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025463\n",
      "         Iterations: 111\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023583\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025692\n",
      "         Iterations: 100\n",
      "         Function evaluations: 1751\n",
      "         Gradient evaluations: 103\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025121\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Bootstrap iteration 39 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021392\n",
      "         Iterations: 110\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022479\n",
      "         Iterations: 114\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014452\n",
      "         Iterations: 77\n",
      "         Function evaluations: 1343\n",
      "         Gradient evaluations: 79\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023635\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023385\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.012542\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Bootstrap iteration 45 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020075\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Bootstrap iteration 46 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023585\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018889\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024801\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024253\n",
      "         Iterations: 95\n",
      "         Function evaluations: 1649\n",
      "         Gradient evaluations: 97\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020790\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Bootstrap iteration 51 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018247\n",
      "         Iterations: 113\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019086\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016055\n",
      "         Iterations: 144\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016277\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2414\n",
      "         Gradient evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019689\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017948\n",
      "         Iterations: 116\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024410\n",
      "         Iterations: 122\n",
      "         Function evaluations: 2108\n",
      "         Gradient evaluations: 124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017150\n",
      "         Iterations: 73\n",
      "         Function evaluations: 1275\n",
      "         Gradient evaluations: 75\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021716\n",
      "         Iterations: 104\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015263\n",
      "         Iterations: 116\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017680\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2057\n",
      "         Gradient evaluations: 121\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024338\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022535\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1836\n",
      "         Gradient evaluations: 108\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018043\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016591\n",
      "         Iterations: 103\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021930\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014157\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016455\n",
      "         Iterations: 120\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017165\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025945\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022975\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019969\n",
      "         Iterations: 115\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017592\n",
      "         Iterations: 123\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Bootstrap iteration 74 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024940\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018333\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019262\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Bootstrap iteration 77 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025349\n",
      "         Iterations: 121\n",
      "         Function evaluations: 2091\n",
      "         Gradient evaluations: 123\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008153\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016228\n",
      "         Iterations: 109\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025509\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020368\n",
      "         Iterations: 107\n",
      "         Function evaluations: 1870\n",
      "         Gradient evaluations: 110\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021557\n",
      "         Iterations: 67\n",
      "         Function evaluations: 1207\n",
      "         Gradient evaluations: 71\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016805\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Bootstrap iteration 84 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026216\n",
      "         Iterations: 92\n",
      "         Function evaluations: 1598\n",
      "         Gradient evaluations: 94\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018299\n",
      "         Iterations: 98\n",
      "         Function evaluations: 1717\n",
      "         Gradient evaluations: 101\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014594\n",
      "         Iterations: 115\n",
      "         Function evaluations: 1989\n",
      "         Gradient evaluations: 117\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018165\n",
      "         Iterations: 105\n",
      "         Function evaluations: 1853\n",
      "         Gradient evaluations: 109\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026995\n",
      "         Iterations: 109\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017716\n",
      "         Iterations: 139\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022609\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017556\n",
      "         Iterations: 97\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025541\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009393\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Bootstrap iteration 94 failed: Singular matrix\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022920\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2074\n",
      "         Gradient evaluations: 122\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019816\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.029347\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018882\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021320\n",
      "         Iterations: 108\n",
      "         Function evaluations: 1887\n",
      "         Gradient evaluations: 111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boostrapped SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.004520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Boostrapped SE\n",
       "sblack           0.003955\n",
       "shispanic        0.004520\n",
       "sother           0.003933"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bootstrap SEs\n",
    "se = probit.bootstrap(y, x, probit_results['theta'], indices, nB=100)\n",
    "formatted_se =pd.DataFrame(se, index=[\"sblack\", \"shispanic\", \"sother\"], columns=[\"Boostrapped SE\"]).round(6)\n",
    "formatted_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             APE      s.e.         t   p-value\n",
      "Var                                           \n",
      "sblack     0.002  0.003955  0.505689  0.613075\n",
      "shispanic  0.006  0.004520  1.327434  0.184365\n",
      "sother     0.001  0.003933  0.254259  0.799296\n"
     ]
    }
   ],
   "source": [
    "tab = pd.DataFrame({\n",
    "    'APE': res_probit['Estimate'],\n",
    "    's.e.': formatted_se['Boostrapped SE']\n",
    "})\n",
    "tab['t'] = tab['APE'] / tab['s.e.']\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values\n",
    "tab.index.name = 'Var'\n",
    "tab = tab.round(6)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Estimate\n",
       "sblack        0.002\n",
       "shispanic     0.005\n",
       "sother       -0.000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimating the average partial effects using the logit\n",
    "indices = [x_lab.index('sblack'), x_lab.index('shisp'), x_lab.index('sother')]  \n",
    "labels = ['sblack', 'shispanic', 'sother']  \n",
    "\n",
    "#Print the average partial effects \n",
    "res_logit = logit.properties(x, logit_results['theta'],print_out = True,se=True,indices=indices, labels = labels)\n",
    "res_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014926\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018720\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015215\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021452\n",
      "         Iterations: 157\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025087\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1921\n",
      "         Gradient evaluations: 113\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018475\n",
      "         Iterations: 137\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021360\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021166\n",
      "         Iterations: 157\n",
      "         Function evaluations: 2686\n",
      "         Gradient evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020577\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011741\n",
      "         Iterations: 148\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019410\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016313\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024127\n",
      "         Iterations: 144\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021660\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027080\n",
      "         Iterations: 144\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026303\n",
      "         Iterations: 125\n",
      "         Function evaluations: 2142\n",
      "         Gradient evaluations: 126\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014260\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2856\n",
      "         Gradient evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021232\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025672\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016456\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025138\n",
      "         Iterations: 173\n",
      "         Function evaluations: 2992\n",
      "         Gradient evaluations: 176\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018648\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015795\n",
      "         Iterations: 149\n",
      "         Function evaluations: 2550\n",
      "         Gradient evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019550\n",
      "         Iterations: 119\n",
      "         Function evaluations: 2040\n",
      "         Gradient evaluations: 120\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022965\n",
      "         Iterations: 142\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020546\n",
      "         Iterations: 165\n",
      "         Function evaluations: 2822\n",
      "         Gradient evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021335\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018253\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021562\n",
      "         Iterations: 176\n",
      "         Function evaluations: 3009\n",
      "         Gradient evaluations: 177\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015686\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2312\n",
      "         Gradient evaluations: 136\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020255\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020986\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008956\n",
      "         Iterations: 148\n",
      "         Function evaluations: 2533\n",
      "         Gradient evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026194\n",
      "         Iterations: 173\n",
      "         Function evaluations: 2958\n",
      "         Gradient evaluations: 174\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021663\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2227\n",
      "         Gradient evaluations: 131\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018432\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021150\n",
      "         Iterations: 129\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021112\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2465\n",
      "         Gradient evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.026159\n",
      "         Iterations: 140\n",
      "         Function evaluations: 2397\n",
      "         Gradient evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011792\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018268\n",
      "         Iterations: 156\n",
      "         Function evaluations: 2669\n",
      "         Gradient evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011196\n",
      "         Iterations: 157\n",
      "         Function evaluations: 2703\n",
      "         Gradient evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022580\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2193\n",
      "         Gradient evaluations: 129\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011639\n",
      "         Iterations: 160\n",
      "         Function evaluations: 2737\n",
      "         Gradient evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022726\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016460\n",
      "         Iterations: 135\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022262\n",
      "         Iterations: 147\n",
      "         Function evaluations: 2516\n",
      "         Gradient evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022913\n",
      "         Iterations: 160\n",
      "         Function evaluations: 2737\n",
      "         Gradient evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020315\n",
      "         Iterations: 84\n",
      "         Function evaluations: 1445\n",
      "         Gradient evaluations: 85\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014207\n",
      "         Iterations: 143\n",
      "         Function evaluations: 2448\n",
      "         Gradient evaluations: 144\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020066\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013795\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2363\n",
      "         Gradient evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020495\n",
      "         Iterations: 158\n",
      "         Function evaluations: 2703\n",
      "         Gradient evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024681\n",
      "         Iterations: 111\n",
      "         Function evaluations: 1938\n",
      "         Gradient evaluations: 114\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022067\n",
      "         Iterations: 99\n",
      "         Function evaluations: 1700\n",
      "         Gradient evaluations: 100\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019467\n",
      "         Iterations: 127\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018549\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019541\n",
      "         Iterations: 159\n",
      "         Function evaluations: 2771\n",
      "         Gradient evaluations: 163\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015986\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020154\n",
      "         Iterations: 179\n",
      "         Function evaluations: 3060\n",
      "         Gradient evaluations: 180\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024952\n",
      "         Iterations: 83\n",
      "         Function evaluations: 1428\n",
      "         Gradient evaluations: 84\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010677\n",
      "         Iterations: 133\n",
      "         Function evaluations: 2278\n",
      "         Gradient evaluations: 134\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018859\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024868\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2346\n",
      "         Gradient evaluations: 138\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017163\n",
      "         Iterations: 111\n",
      "         Function evaluations: 1904\n",
      "         Gradient evaluations: 112\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027085\n",
      "         Iterations: 124\n",
      "         Function evaluations: 2125\n",
      "         Gradient evaluations: 125\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018088\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014086\n",
      "         Iterations: 156\n",
      "         Function evaluations: 2669\n",
      "         Gradient evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017731\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.028812\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2601\n",
      "         Gradient evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025290\n",
      "         Iterations: 174\n",
      "         Function evaluations: 2975\n",
      "         Gradient evaluations: 175\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022286\n",
      "         Iterations: 180\n",
      "         Function evaluations: 3094\n",
      "         Gradient evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018064\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025853\n",
      "         Iterations: 91\n",
      "         Function evaluations: 1581\n",
      "         Gradient evaluations: 93\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023971\n",
      "         Iterations: 112\n",
      "         Function evaluations: 1955\n",
      "         Gradient evaluations: 115\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.017460\n",
      "         Iterations: 163\n",
      "         Function evaluations: 2788\n",
      "         Gradient evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015356\n",
      "         Iterations: 102\n",
      "         Function evaluations: 1768\n",
      "         Gradient evaluations: 104\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.025046\n",
      "         Iterations: 158\n",
      "         Function evaluations: 2720\n",
      "         Gradient evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023888\n",
      "         Iterations: 141\n",
      "         Function evaluations: 2431\n",
      "         Gradient evaluations: 143\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019160\n",
      "         Iterations: 151\n",
      "         Function evaluations: 2584\n",
      "         Gradient evaluations: 152\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019460\n",
      "         Iterations: 132\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020076\n",
      "         Iterations: 118\n",
      "         Function evaluations: 2023\n",
      "         Gradient evaluations: 119\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019862\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024158\n",
      "         Iterations: 125\n",
      "         Function evaluations: 2159\n",
      "         Gradient evaluations: 127\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.019375\n",
      "         Iterations: 160\n",
      "         Function evaluations: 2737\n",
      "         Gradient evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021009\n",
      "         Iterations: 146\n",
      "         Function evaluations: 2499\n",
      "         Gradient evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.020339\n",
      "         Iterations: 160\n",
      "         Function evaluations: 2737\n",
      "         Gradient evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023619\n",
      "         Iterations: 126\n",
      "         Function evaluations: 2176\n",
      "         Gradient evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.021192\n",
      "         Iterations: 117\n",
      "         Function evaluations: 2006\n",
      "         Gradient evaluations: 118\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014178\n",
      "         Iterations: 166\n",
      "         Function evaluations: 2839\n",
      "         Gradient evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023550\n",
      "         Iterations: 134\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 135\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015038\n",
      "         Iterations: 167\n",
      "         Function evaluations: 2856\n",
      "         Gradient evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018923\n",
      "         Iterations: 166\n",
      "         Function evaluations: 2839\n",
      "         Gradient evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015858\n",
      "         Iterations: 145\n",
      "         Function evaluations: 2482\n",
      "         Gradient evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015612\n",
      "         Iterations: 152\n",
      "         Function evaluations: 2618\n",
      "         Gradient evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022882\n",
      "         Iterations: 128\n",
      "         Function evaluations: 2210\n",
      "         Gradient evaluations: 130\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015643\n",
      "         Iterations: 130\n",
      "         Function evaluations: 2244\n",
      "         Gradient evaluations: 132\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023697\n",
      "         Iterations: 138\n",
      "         Function evaluations: 2380\n",
      "         Gradient evaluations: 140\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.015206\n",
      "         Iterations: 136\n",
      "         Function evaluations: 2329\n",
      "         Gradient evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016177\n",
      "         Iterations: 131\n",
      "         Function evaluations: 2261\n",
      "         Gradient evaluations: 133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boostrapped SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sblack</th>\n",
       "      <td>0.004719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shispanic</th>\n",
       "      <td>0.004599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sother</th>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Boostrapped SE\n",
       "sblack           0.004719\n",
       "shispanic        0.004599\n",
       "sother           0.003703"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bootstrap SEs\n",
    "se = logit.bootstrap(y, x, logit_results['theta'], indices, nB=100)\n",
    "formatted_se =pd.DataFrame(se, index=[\"sblack\", \"shispanic\", \"sother\"], columns=[\"Boostrapped SE\"]).round(6)\n",
    "formatted_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             APE      s.e.         t   p-value\n",
      "Var                                           \n",
      "sblack     0.002  0.004719  0.423819  0.671698\n",
      "shispanic  0.005  0.004599  1.087193  0.276952\n",
      "sother    -0.000  0.003703 -0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "tab = pd.DataFrame({\n",
    "    'APE': res_logit['Estimate'],\n",
    "    's.e.': formatted_se['Boostrapped SE']\n",
    "})\n",
    "tab['t'] = tab['APE'] / tab['s.e.']\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values\n",
    "tab.index.name = 'Var'\n",
    "tab = tab.round(6)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining different fixed vectors\n",
    "\n",
    "Obs: This only works for the model with all variables included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sage</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "      <th>sagesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_me</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  sblack  shisp  sother  smale  sage  sempl  sincome  spop  \\\n",
       "x_me    1.0     0.0    0.0     0.0    1.0   2.5    0.0      1.0   4.0   \n",
       "\n",
       "      daytime  inctype_lin  omajblack  omajhisp  omajother  sbehavior  sagesq  \n",
       "x_me      5.0          1.0        0.0       0.0        0.0        1.0    6.25  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make vector of stereotypical white young man \n",
    "x_lab = ['const', 'sblack', 'shisp', 'sother', \n",
    "         'smale', 'sage', 'sempl', 'sincome',\n",
    "         'spop', 'daytime', 'inctype_lin', 'omajblack',\n",
    "         'omajhisp', 'omajother', 'sbehavior','sagesq']\n",
    "\n",
    "x_me = np.array([1, 0, 0, 0,\n",
    "                 1, 2.5, 0, 1,\n",
    "                 4, 5, 1, 0, \n",
    "                 0, 0, 1, 6.25]).reshape(1, -1)\n",
    "\n",
    "pd.DataFrame(x_me, columns=x_lab, index=['x_me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make vector of stereotypical white old woman\n",
    "#x_lab = ['const', 'sblack', 'shisp', 'sother', \n",
    "#         'smale', 'sage', 'sempl', 'sincome',\n",
    "#         'spop', 'daytime', 'inctype_lin', 'omajblack',\n",
    "#         'omajhisp', 'omajother', 'sbehavior','sagesq']\n",
    "\n",
    "#x_me = np.array([1, 0, 0, 0,\n",
    "#                 0, 4.5, 1, 3,\n",
    "#                 2, 2, 1, 0, \n",
    "#                 0, 0, 1, 20.25]).reshape(1, -1)\n",
    "\n",
    "#pd.DataFrame(x_me, columns=x_lab, index=['x_me'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switcing race "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>sblack</th>\n",
       "      <th>shisp</th>\n",
       "      <th>sother</th>\n",
       "      <th>smale</th>\n",
       "      <th>sage</th>\n",
       "      <th>sempl</th>\n",
       "      <th>sincome</th>\n",
       "      <th>spop</th>\n",
       "      <th>daytime</th>\n",
       "      <th>inctype_lin</th>\n",
       "      <th>omajblack</th>\n",
       "      <th>omajhisp</th>\n",
       "      <th>omajother</th>\n",
       "      <th>sbehavior</th>\n",
       "      <th>sagesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_me2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       const  sblack  shisp  sother  smale  sage  sempl  sincome  spop  \\\n",
       "x_me2    1.0     1.0    0.0     0.0    1.0   2.5    0.0      1.0   4.0   \n",
       "\n",
       "       daytime  inctype_lin  omajblack  omajhisp  omajother  sbehavior  sagesq  \n",
       "x_me2      5.0          1.0        0.0       0.0        0.0        1.0    6.25  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k=1: black \n",
    "#k=2: hispanic\n",
    "#k=3: other\n",
    "\n",
    "k = 1\n",
    "x_me2 = x_me.copy()\n",
    "x_me2[:, k] = 1   \n",
    "pd.DataFrame(x_me2, columns=x_lab, index=['x_me2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch coef from probit model\n",
    "b_pr = probit_tab.theta.values\n",
    "#Find marginal effect as difference in predicted probabilities\n",
    "me_race_pr = probit.G(x_me2@b_pr) - probit.G(x_me@b_pr) \n",
    "#Calculate gradient\n",
    "gx0 = norm.pdf(x_me@b_pr)\n",
    "gx2 = norm.pdf(x_me2@b_pr)\n",
    "grad_d_pr = gx2*x_me2 - gx0*x_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to calculate std. errors\n",
    "def get_se(grad, cov):\n",
    "    #Calculate variance-covariance matrix\n",
    "    cov_me = grad@cov@grad.T\n",
    "    #Return squareroot of variance \n",
    "    return np.sqrt(np.diag(cov_me))\n",
    "\n",
    "se_d_pr = get_se(grad_d_pr, probit_results['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marginal Effect</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>t</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00278</td>\n",
       "      <td>0.01348</td>\n",
       "      <td>0.206198</td>\n",
       "      <td>0.836636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Marginal Effect     s.e.         t   p-value\n",
       "Var                                              \n",
       "0            0.00278  0.01348  0.206198  0.836636"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create table with results\n",
    "me_dict = {'Marginal Effect': me_race_pr[0],\n",
    "           's.e.':            se_d_pr}\n",
    "tab = pd.DataFrame(me_dict)\n",
    "tab['t'] = tab['Marginal Effect'] / tab['s.e.']\n",
    "tab.index.name = 'Var'\n",
    "#Find p value for marginal effects\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values\n",
    "\n",
    "tab.to_latex('me_probit_youngman_black.tex') #change for old womand and race!\n",
    "tab.round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch coef from logit model\n",
    "b_lg = logit_tab.theta.values\n",
    "#Cal diff in predicted probabilities\n",
    "me_race_lg = logit.G(x_me2@b_lg) - logit.G(x_me@b_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the logistic function exponential terms for x_me2 and x_me\n",
    "exp_x0_b = np.exp(-(x_me@b_lg))\n",
    "exp_x2_b = np.exp(-(x_me2@b_lg))\n",
    "grad_d_lg = (x_me2 * exp_x2_b)/ (1 + exp_x2_b)**2 - (x_me * exp_x0_b)/ (1 + exp_x0_b)**2\n",
    "#Calculate standard errors\n",
    "se_d_lg = get_se(grad_d_lg, logit_results['cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marginal Effect</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>t</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.203149</td>\n",
       "      <td>0.839018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Marginal Effect      s.e.         t   p-value\n",
       "Var                                               \n",
       "0             0.0006  0.002952  0.203149  0.839018"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_dict = {'Marginal Effect': me_race_lg[0],\n",
    "           's.e.':            se_d_lg}\n",
    "tab = pd.DataFrame(me_dict)\n",
    "tab['t'] = tab['Marginal Effect'] / tab['s.e.']\n",
    "tab.index.name = 'Var'\n",
    "#Find p value for marginal effects\n",
    "p_values = 2 * (1 - norm.cdf(np.abs(tab['t'])))\n",
    "tab['p-value'] = p_values\n",
    "\n",
    "tab.to_latex('me_logit_youngman_black.tex') #change for old womand and race!\n",
    "tab.round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with probit and logit results for marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'me_probit_youngman.tex',\n",
    "    'me_probit_youngman_hisp.tex',\n",
    "    'me_logit_youngman.tex',\n",
    "    'me_logit_youngman_hisp.tex',\n",
    "    'me_probit_old_woman.tex',\n",
    "    'me_probit_old_woman_hisp.tex',\n",
    "    'me_logit_old_woman.tex',\n",
    "    'me_logit_old_woman.tex'\n",
    "]\n",
    "\n",
    "with open('combined_table.tex', 'w') as outfile:\n",
    "    outfile.write(r'\\begin{table}[ht!]' + '\\n')\n",
    "    outfile.write(r'\\centering' + '\\n')\n",
    "    outfile.write(r'\\caption{Marginal Effects from Probit and Logit Models}' + '\\n')\n",
    "    outfile.write(r'\\begin{tabular}{lccc}' + '\\n')\n",
    "    outfile.write(r'\\toprule' + '\\n')\n",
    "    \n",
    "    panels = ['Panel A: Probit, Young Man',\n",
    "              'Panel B: Probit, Young Man Hispanic',\n",
    "              'Panel C: Logit, young man',\n",
    "              'Panel D: Logit, young man, hispanic',\n",
    "              'Panel E: Probit, Old Woman',\n",
    "              'Panel F: Probit, Old Woman, hispanic',\n",
    "              'Panel G: Logit, Old Woman',\n",
    "              'Panel H: Logit, Old Woman, hispanic']\n",
    "\n",
    "    for panel_name, fname in zip(panels, files):\n",
    "        outfile.write(r'\\midrule' + '\\n')\n",
    "        outfile.write(r'\\multicolumn{4}{c}{\\textbf{' + panel_name + r'}} \\\\' + '\\n')\n",
    "        outfile.write(r'\\midrule' + '\\n')\n",
    "        with open(fname) as infile:\n",
    "            content = infile.read()\n",
    "            outfile.write(content + '\\n')\n",
    "    \n",
    "    outfile.write(r'\\bottomrule' + '\\n')\n",
    "    outfile.write(r'\\end{tabular}' + '\\n')\n",
    "    outfile.write(r'\\end{table}' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM test of probit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030440\n",
      "         Iterations: 37\n",
      "         Function evaluations: 195\n",
      "         Gradient evaluations: 39\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: smale, sempl, sincome, spop, sage, sagesq\n",
      "Degrees of freedom: 6\n",
      "LM Test Statistic: 23.5037\n",
      "P-value: 0.0006\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: daytime, inctype_lin, omajblack, omajhisp, omajother\n",
      "Degrees of freedom: 5\n",
      "LM Test Statistic: 2.4918\n",
      "P-value: 0.7777\n",
      "------------------------------------------------------------\n",
      "Result: Fail to reject H0 - additional variables are not significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: sbehavior\n",
      "Degrees of freedom: 1\n",
      "LM Test Statistic: 58.9636\n",
      "P-value: 0.0000\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#Conduct LM tests of different model formulations\n",
    "y_lab = 'anyuseofforce_coded'\n",
    "x_lab_restricted = ['const', 'sblack', 'shisp', 'sother']\n",
    "x_restricted = dat[x_lab_restricted].values\n",
    "\n",
    "#Estimate restricted model\n",
    "theta0 = probit.starting_values(y, x_restricted)\n",
    "results_restricted = est.estimate(probit.q, theta0, y, x_restricted)\n",
    "theta_restricted = results_restricted['theta']\n",
    "\n",
    "#Prepare the additional variables to test\n",
    "# first augmentation\n",
    "x_lab_additional_1 = ['smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "x_additional_1 = dat[x_lab_additional_1].values\n",
    "# second augmentation\n",
    "x_lab_additional_2 = ['daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_additional_2 = dat[x_lab_additional_2].values\n",
    "# third augmentation\n",
    "x_lab_additional_3 = ['sbehavior']\n",
    "x_additional_3 = dat[x_lab_additional_3].values\n",
    "\n",
    "#Run the LM test\n",
    "# first augmentation\n",
    "stat, pval, df = probit.LM_test(y, x_restricted, theta_restricted, x_additional_1)\n",
    "# second\n",
    "stat2, pval2, df2 = probit.LM_test(y, x_restricted, theta_restricted, x_additional_2)\n",
    "#third\n",
    "stat3, pval3, df3 = probit.LM_test(y, x_restricted, theta_restricted, x_additional_3)\n",
    "#Print results\n",
    "probit.print_LM_test(stat, pval, df, var_names=x_lab_additional_1)\n",
    "probit.print_LM_test(stat2, pval2, df2, var_names=x_lab_additional_2)\n",
    "probit.print_LM_test(stat3, pval3, df3, var_names=x_lab_additional_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM test of logit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030440\n",
      "         Iterations: 51\n",
      "         Function evaluations: 265\n",
      "         Gradient evaluations: 53\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: smale, sempl, sincome, spop, sage, sagesq\n",
      "Degrees of freedom: 6\n",
      "LM Test Statistic: 23.5757\n",
      "P-value: 0.0006\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: daytime, inctype_lin, omajblack, omajhisp, omajother\n",
      "Degrees of freedom: 5\n",
      "LM Test Statistic: 2.5265\n",
      "P-value: 0.7725\n",
      "------------------------------------------------------------\n",
      "Result: Fail to reject H0 - additional variables are not significant\n",
      "============================================================\n",
      "\n",
      "Lagrange Multiplier (LM) Test for Variable Inclusion\n",
      "============================================================\n",
      "Testing inclusion of: sbehavior\n",
      "Degrees of freedom: 1\n",
      "LM Test Statistic: 56.7351\n",
      "P-value: 0.0000\n",
      "------------------------------------------------------------\n",
      "Result: Reject H0 at 1% level - additional variables are significant\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# conduct LM tests of different model formulations\n",
    "y_lab = 'anyuseofforce_coded'\n",
    "x_lab_restricted = ['const', 'sblack', 'shisp', 'sother']\n",
    "x_restricted = dat[x_lab_restricted].values\n",
    "\n",
    "#Estimate restricted model\n",
    "theta0 = logit.starting_values(y, x_restricted)\n",
    "results_restricted = est.estimate(logit.q, theta0, y, x_restricted)\n",
    "theta_restricted = results_restricted['theta']\n",
    "\n",
    "#Prepare the additional variables to test\n",
    "# first augmentation\n",
    "x_lab_additional_1 = ['smale', 'sempl', 'sincome', 'spop', 'sage', 'sagesq']\n",
    "x_additional_1 = dat[x_lab_additional_1].values\n",
    "# second augmentation\n",
    "x_lab_additional_2 = ['daytime', 'inctype_lin', 'omajblack', 'omajhisp', 'omajother']\n",
    "x_additional_2 = dat[x_lab_additional_2].values\n",
    "# third augmentation\n",
    "x_lab_additional_3 = ['sbehavior']\n",
    "x_additional_3 = dat[x_lab_additional_3].values\n",
    "\n",
    "#Run the LM test\n",
    "# first augmentation\n",
    "stat, pval, df = logit.LM_test(y, x_restricted, theta_restricted, x_additional_1)\n",
    "# second\n",
    "stat2, pval2, df2 = logit.LM_test(y, x_restricted, theta_restricted, x_additional_2)\n",
    "#third\n",
    "stat3, pval3, df3 = logit.LM_test(y, x_restricted, theta_restricted, x_additional_3)\n",
    "#Print results\n",
    "logit.print_LM_test(stat, pval, df, var_names=x_lab_additional_1)\n",
    "logit.print_LM_test(stat2, pval2, df2, var_names=x_lab_additional_2)\n",
    "logit.print_LM_test(stat3, pval3, df3, var_names=x_lab_additional_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
